I just wrote a script that dumps our enormous database, compresses it, splits it in to 500MB chunks, and uploads it to S3 (with 5 concurrent connections).